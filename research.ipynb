{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvpmoneesha/QR-Code/blob/main/research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPKRcwqF1zda",
        "outputId": "023d800b-2a47-44b8-eb5d-e8a773975f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6soTG7G8Gl3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-GsOAow9pqE"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zE3JwB-8BOh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzqFY5xi91HB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# System libraries\n",
        "from pathlib import Path\n",
        "import os.path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nwOTkefVvaE",
        "outputId": "2f88c4d9-f749-4ca0-cee8-236a8ba75bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-07-30 07:04:27--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-07-30 07:04:27 (25.2 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for our notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwiRXfnZTWwk"
      },
      "source": [
        "### Load and Transform Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eBmOSTHThwm"
      },
      "outputs": [],
      "source": [
        "TARGET_SIZE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poSHNSnjTygD",
        "outputId": "e86e9baf-dcd2-4ef9-d745-9499303ddc27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 7 directories and 0 images in 'drive/MyDrive/research/Train'.\n",
            "There are 0 directories and 250 images in 'drive/MyDrive/research/Train/Bacterial gill disease'.\n",
            "There are 0 directories and 250 images in 'drive/MyDrive/research/Train/Bacterial diseases - Aeromoniasis'.\n",
            "There are 0 directories and 250 images in 'drive/MyDrive/research/Train/Bacterial Red disease'.\n",
            "There are 0 directories and 250 images in 'drive/MyDrive/research/Train/Parasitic diseases'.\n",
            "There are 0 directories and 250 images in 'drive/MyDrive/research/Train/Fungal diseases Saprolegniasis'.\n",
            "There are 0 directories and 250 images in 'drive/MyDrive/research/Train/Viral diseases White tail disease'.\n",
            "There are 0 directories and 250 images in 'drive/MyDrive/research/Train/Healthy Fish'.\n"
          ]
        }
      ],
      "source": [
        "# Walk through each directory\n",
        "dataset = \"drive/MyDrive/research/Train\"\n",
        "walk_through_dir(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lnG3WsKezdT"
      },
      "source": [
        "### Create a Dataframe for Image Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7S_OvpjT369"
      },
      "outputs": [],
      "source": [
        "def convert_path_to_df(dataset):\n",
        "    image_dir = Path(dataset)\n",
        "\n",
        "    # Get filepaths and labels\n",
        "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.jpeg')) + list(image_dir.glob(r'**/*.PNG'))\n",
        "\n",
        "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "    labels = pd.Series(labels, name='Label')\n",
        "\n",
        "    # Concatenate filepaths and labels\n",
        "    image_df = pd.concat([filepaths, labels], axis=1)\n",
        "    return image_df\n",
        "\n",
        "image_df = convert_path_to_df(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCeWCZne97D2"
      },
      "source": [
        "### Data split into Train, Validation, and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm_t5YMK90Sx",
        "outputId": "b20ce926-315c-4920-8687-0fb0548a3771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1099, Validation: 275, Test: 344\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train-test split (80% train, 20% test)\n",
        "train_df, test_df = train_test_split(image_df, test_size=0.2, stratify=image_df['Label'], random_state=42)\n",
        "\n",
        "# Further split training into train and validation (80% of 80% = 64% train, 16% val)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['Label'], random_state=42)\n",
        "\n",
        "print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcQ7-aRi_ZMw"
      },
      "source": [
        "### Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3l5WcL5YSbV"
      },
      "outputs": [],
      "source": [
        "# Train: use data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Validation and Test: only rescaling\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owUPgjvMFzpo"
      },
      "source": [
        "### Create Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buA7xzLy_jN3",
        "outputId": "dd243cce-7890-4ed9-d67b-b8648a3ea591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1099 validated image filenames belonging to 7 classes.\n",
            "Found 275 validated image filenames belonging to 7 classes.\n",
            "Found 344 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_gen = val_test_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "test_gen = val_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    batch_size=32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycZ3ahsrhyXz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16, ResNet50, ResNet152\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Get number of classes\n",
        "num_classes = len(train_gen.class_indices)\n",
        "\n",
        "# Function to build model\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el-s98nTjEch",
        "outputId": "b33192c7-375c-4345-ad49-5c014362d24c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2567s\u001b[0m 73s/step - accuracy: 0.1496 - loss: 2.8476 - val_accuracy: 0.1382 - val_loss: 1.9458\n",
            "Epoch 2/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2507s\u001b[0m 72s/step - accuracy: 0.1506 - loss: 1.9474 - val_accuracy: 0.1418 - val_loss: 1.9459\n",
            "Epoch 3/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2541s\u001b[0m 72s/step - accuracy: 0.1203 - loss: 1.9463 - val_accuracy: 0.1418 - val_loss: 1.9459\n",
            "Epoch 4/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2531s\u001b[0m 71s/step - accuracy: 0.1379 - loss: 1.9460 - val_accuracy: 0.1418 - val_loss: 1.9459\n",
            "Epoch 5/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2497s\u001b[0m 71s/step - accuracy: 0.1603 - loss: 1.9460 - val_accuracy: 0.1418 - val_loss: 1.9459\n",
            "Epoch 6/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2531s\u001b[0m 72s/step - accuracy: 0.1448 - loss: 1.9460 - val_accuracy: 0.1418 - val_loss: 1.9459\n",
            "Epoch 7/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2492s\u001b[0m 71s/step - accuracy: 0.1504 - loss: 1.9459 - val_accuracy: 0.1418 - val_loss: 1.9459\n",
            "Epoch 8/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2515s\u001b[0m 72s/step - accuracy: 0.1378 - loss: 1.9461 - val_accuracy: 0.1455 - val_loss: 1.9459\n",
            "Epoch 9/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2520s\u001b[0m 72s/step - accuracy: 0.1513 - loss: 1.9457 - val_accuracy: 0.1455 - val_loss: 1.9459\n",
            "Epoch 10/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2482s\u001b[0m 71s/step - accuracy: 0.1171 - loss: 1.9462 - val_accuracy: 0.1418 - val_loss: 1.9459\n",
            "VGG16 Accuracy: 0.14181818068027496\n"
          ]
        }
      ],
      "source": [
        "base_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model_vgg = build_model(base_vgg)\n",
        "\n",
        "model_vgg.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_vgg = model_vgg.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "\n",
        "print(\"VGG16 Accuracy:\", history_vgg.history['val_accuracy'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDLNO8Y1hj4g",
        "outputId": "51c9ed7a-3e3b-4b65-f0f8-7753b0cc6a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1062s\u001b[0m 29s/step - accuracy: 0.3695 - loss: 1.8862 - val_accuracy: 0.1418 - val_loss: 69.1875\n",
            "Epoch 2/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m968s\u001b[0m 28s/step - accuracy: 0.3976 - loss: 1.6377 - val_accuracy: 0.1564 - val_loss: 2.3489\n",
            "Epoch 3/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m971s\u001b[0m 28s/step - accuracy: 0.4980 - loss: 1.4140 - val_accuracy: 0.1418 - val_loss: 5.8170\n",
            "Epoch 4/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m960s\u001b[0m 27s/step - accuracy: 0.5524 - loss: 1.2821 - val_accuracy: 0.1709 - val_loss: 2.3970\n",
            "Epoch 5/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m963s\u001b[0m 28s/step - accuracy: 0.6192 - loss: 1.1146 - val_accuracy: 0.1455 - val_loss: 81.6132\n",
            "Epoch 6/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m962s\u001b[0m 28s/step - accuracy: 0.6483 - loss: 0.9810 - val_accuracy: 0.1418 - val_loss: 8.6500\n",
            "Epoch 7/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m985s\u001b[0m 28s/step - accuracy: 0.7019 - loss: 0.9112 - val_accuracy: 0.1418 - val_loss: 2.6314\n",
            "Epoch 8/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m965s\u001b[0m 28s/step - accuracy: 0.6988 - loss: 0.8659 - val_accuracy: 0.1345 - val_loss: 3.9145\n",
            "Epoch 9/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m991s\u001b[0m 28s/step - accuracy: 0.7249 - loss: 0.7808 - val_accuracy: 0.1418 - val_loss: 3.8487\n",
            "Epoch 10/10\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m958s\u001b[0m 27s/step - accuracy: 0.7978 - loss: 0.5826 - val_accuracy: 0.1418 - val_loss: 5.6871\n",
            "ResNet50 Accuracy: 0.14181818068027496\n"
          ]
        }
      ],
      "source": [
        "base_res50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model_res50 = build_model(base_res50)\n",
        "\n",
        "model_res50.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_res50 = model_res50.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "\n",
        "print(\"ResNet50 Accuracy:\", history_res50.history['val_accuracy'][-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLiqEDTk8GdF"
      },
      "outputs": [],
      "source": [
        "base_res152 = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model_res152 = build_model(base_res152)\n",
        "\n",
        "model_res152.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_res152 = model_res152.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "\n",
        "print(\"ResNet152 Accuracy:\", history_res152.history['val_accuracy'][-1])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "177nkQmX-D-0d1xLZ5JDaBRWZhilrYLUf",
      "authorship_tag": "ABX9TyPsPEZ1ScVFUWIbLw4tewcj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}